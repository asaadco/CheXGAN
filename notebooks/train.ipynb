{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b226d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Initial convolution block\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(1, 64, 7, stride=1,),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Downsampling\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Residual blocks\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "            ResidualBlock(256),\n",
    "\n",
    "            # Upsampling\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Output layer\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, 1, 7),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.res = nn.Sequential(nn.ReflectionPad2d(1),\n",
    "                                 nn.Conv2d(in_channels, in_channels, 3, stride=1),\n",
    "                                 nn.InstanceNorm2d(in_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.ReflectionPad2d(1),\n",
    "                                 nn.Conv2d(in_channels, in_channels, 3, stride=1),\n",
    "                                 nn.InstanceNorm2d(in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.res(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7824f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, unaligned=False, mode=\"train\", A=\"No Finding\", B=\"Pneumonia\"):\n",
    "        efficentMode = True # optional\n",
    "        cwd = os.getcwd()\n",
    "        cwd = cwd[0:cwd.rfind(\"/\")]\n",
    "        db_list = f\"{cwd}/data/Data_toy.csv\"\n",
    "        self.diseases_list = set()\n",
    "        self.disease_count = {} # optional\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        df = pd.read_csv(db_list)\n",
    "        # print(df.head(10))\n",
    "        if not efficentMode:\n",
    "            for i, row in df.iterrows():\n",
    "                    if '|' in row[1]:\n",
    "                        diseases = row[1].split('|')\n",
    "                        for d in diseases:\n",
    "                            self.diseases_list.add(d)\n",
    "                            if d not in df:\n",
    "                                df[d] = 0\n",
    "                                df.loc[i, d] = 1\n",
    "                            else:\n",
    "                                df.loc[i, d] = 1\n",
    "                    else:\n",
    "                        d = str(row[1])\n",
    "                        self.diseases_list.add(d)\n",
    "                        self.disease_count[d] = self.disease_count.get(d, 0) + 1\n",
    "                        if d not in df:\n",
    "                            df[d] = 0\n",
    "                            df.loc[i, d] = 1\n",
    "                        else:\n",
    "                            df.loc[i, d] = 1\n",
    "        else:\n",
    "            A_df = df[df[\"Finding Labels\"] == \"No Finding\"]\n",
    "            B_df = df[df[\"Finding Labels\"].str.match(B)]\n",
    "        df.drop(columns=['Finding Labels'], inplace=True) # Optional. Disable if computation takes too long time\n",
    "        # print(diseases_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # A list of image_indices for every disease Hernia_List = [00000003_001.png, 00000003_002.png, 00000003_003.png....]\n",
    "\n",
    "\n",
    "        # After getting one-hot encoding for each diseases, let's create two lists of image indices A and B. For now A will be No-Finding\n",
    "        # and B will be a disease Pneumonia \n",
    "        self.images = {}\n",
    "\n",
    "        # print(images)\n",
    "        if not efficentMode:\n",
    "            for i, d in enumerate(self.diseases_list):\n",
    "                # print(f\"--------------------{d}------------------------\")\n",
    "                self.images[d] = (df[df[d] == 1][\"Image Index\"].to_string(index=False).split(\"\\n\"))\n",
    "\n",
    "        else:\n",
    "            self.images[A] = A_df[\"Image Index\"].to_string(index=False).split(\"\\n\")\n",
    "            self.images[B] = B_df[\"Image Index\"].to_string(index=False).split(\"\\n\")\n",
    "        # print(self.images[B])\n",
    "        # print(self.images)\n",
    "###\n",
    "\n",
    "        self.transform = transform\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        # self.files_A = sorted(glob.glob(os.path.join(root, f\"{mode}/A\") + \"/*.*\"))  # \n",
    "        # self.files_B = sorted(glob.glob(os.path.join(root, f\"{mode}/B\") + \"/*.*\")) # images\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cwd = os.getcwd()\n",
    "        cwd = cwd[0:cwd.rfind(\"/\")]\n",
    "        \n",
    "        A_path = f\"{cwd}/data/images/\"+self.images[self.A][index % len(self.images[self.A])]\n",
    "        if not self.unaligned:\n",
    "            B_path = f\"{cwd}/data/images/\"+self.images[self.B][random.randint(0, len(self.images[self.B]) - 1)]\n",
    "        else:\n",
    "            B_path = f\"{cwd}/data/images/\"+self.images[self.B][index % len(self.images[self.B])]\n",
    "        \n",
    "#         print(A_path)\n",
    "#         print(B_path)       \n",
    "        \n",
    "        A = Image.open(A_path)\n",
    "        B = Image.open(B_path)\n",
    "        A = A.convert(\"L\")\n",
    "        B = B.convert(\"L\")\n",
    "        item_A = self.transform(A)\n",
    "        item_B = self.transform(B)\n",
    "        \n",
    "#         print(\"Pillow\", A.mode, A.size)\n",
    "#         print(\"PIllow\", B.mode, B.size)\n",
    "        return {\"A\": item_A, \"B\": item_B}\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.images[self.A]), len(self.images[self.B]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d759466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayLR:\n",
    "    def __init__(self, epochs, offset, decay_epochs):\n",
    "        epoch_flag = epochs - decay_epochs\n",
    "        assert (epoch_flag > 0), \"Decay must start before the training session ends!\"\n",
    "        self.epochs = epochs\n",
    "        self.offset = offset\n",
    "        self.decay_epochs = decay_epochs\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_epochs) / (\n",
    "                self.epochs - self.decay_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1879e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bf985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "dataset_name = \"CXR\"\n",
    "output_dir = \"outputs\"\n",
    "img_size = 1024\n",
    "batch_size = 1\n",
    "epochs_total = 10\n",
    "print_freq = 100\n",
    "lr_rate = 0.0002\n",
    "decay_epochs = 5\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_dir)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"weights\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset = ImageDataset(root=os.path.join(\"\", dataset_name),\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize(512, Image.BICUBIC),\n",
    "                           transforms.RandomCrop(512),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,))]),\n",
    "                       unaligned=True, A=\"No Finding\", B=\"Mass\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(output_dir, dataset_name, \"A\"))\n",
    "    os.makedirs(os.path.join(output_dir, dataset_name, \"B\"))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(\"weights\", dataset_name))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# create model\n",
    "netG_A2B = Generator().to(device)\n",
    "netG_B2A = Generator().to(device)\n",
    "netD_A = Discriminator().to(device)\n",
    "netD_B = Discriminator().to(device)\n",
    "\n",
    "\n",
    "# netG_A2B = nn.DataParallel(netG_A2B).to(device)\n",
    "# netG_B2A = nn.DataParallel(netG_B2A).to(device)\n",
    "\n",
    "# netD_A = nn.DataParallel(netD_A).to(device)\n",
    "# netD_B = nn.DataParallel(netD_B).to(device)\n",
    "\n",
    "\n",
    "netG_A2B.apply(weights_init)\n",
    "netG_B2A.apply(weights_init)\n",
    "netD_A.apply(weights_init)\n",
    "netD_B.apply(weights_init)\n",
    "\n",
    "# if args.netG_A2B != \"\":\n",
    "#     netG_A2B.load_state_dict(torch.load(args.netG_A2B))\n",
    "# if args.netG_B2A != \"\":\n",
    "#     netG_B2A.load_state_dict(torch.load(args.netG_B2A))\n",
    "# if args.netD_A != \"\":\n",
    "#     netD_A.load_state_dict(torch.load(args.netD_A))\n",
    "# if args.netD_B != \"\":\n",
    "#     netD_B.load_state_dict(torch.load(args.netD_B))\n",
    "\n",
    "# define loss function (adversarial_loss) and optimizer\n",
    "cycle_loss = torch.nn.L1Loss().to(device)\n",
    "identity_loss = torch.nn.L1Loss().to(device)\n",
    "adversarial_loss = torch.nn.MSELoss().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                               lr=lr_rate, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr_rate, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr_rate, betas=(0.5, 0.999))\n",
    "\n",
    "lr_lambda = DecayLR(epochs_total, 0, decay_epochs).step\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "identity_losses = []\n",
    "gan_losses = []\n",
    "cycle_losses = []\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "for epoch in range(0, epochs_total):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, data in progress_bar:\n",
    "        # get batch size data\n",
    "        real_image_A = data[\"A\"].to(device)\n",
    "        real_image_B = data[\"B\"].to(device)\n",
    "        batch_size = real_image_A.size(0)\n",
    "\n",
    "        # real data label is 1, fake data label is 0.\n",
    "        real_label = torch.full((batch_size, 1), 1, device=device, dtype=torch.float32)\n",
    "        fake_label = torch.full((batch_size, 1), 0, device=device, dtype=torch.float32)\n",
    "\n",
    "        ##############################################\n",
    "        # (1) Update G network: Generators A2B and B2A\n",
    "        ##############################################\n",
    "\n",
    "        # Set G_A and G_B's gradients to zero\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        identity_image_A = netG_B2A(real_image_A)\n",
    "        loss_identity_A = identity_loss(identity_image_A, real_image_A) * 5.0\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        identity_image_B = netG_A2B(real_image_B)\n",
    "        loss_identity_B = identity_loss(identity_image_B, real_image_B) * 5.0\n",
    "\n",
    "        # GAN loss\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        fake_image_A = netG_B2A(real_image_B)\n",
    "        fake_output_A = netD_A(fake_image_A)\n",
    "        loss_GAN_B2A = adversarial_loss(fake_output_A, real_label)\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        fake_image_B = netG_A2B(real_image_A)\n",
    "        fake_output_B = netD_B(fake_image_B)\n",
    "        loss_GAN_A2B = adversarial_loss(fake_output_B, real_label)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_image_A = netG_B2A(fake_image_B)\n",
    "        loss_cycle_ABA = cycle_loss(recovered_image_A, real_image_A) * 10.0\n",
    "\n",
    "        recovered_image_B = netG_A2B(fake_image_A)\n",
    "        loss_cycle_BAB = cycle_loss(recovered_image_B, real_image_B) * 10.0\n",
    "\n",
    "        # Combined loss and calculate gradients\n",
    "        errG = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "\n",
    "        # Calculate gradients for G_A and G_B\n",
    "        errG.backward()\n",
    "        # Update G_A and G_B's weights\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update D network: Discriminator A\n",
    "        ##############################################\n",
    "\n",
    "        # Set D_A gradients to zero\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real A image loss\n",
    "        real_output_A = netD_A(real_image_A)\n",
    "        errD_real_A = adversarial_loss(real_output_A, real_label)\n",
    "\n",
    "        # Fake A image loss\n",
    "        fake_image_A = fake_A_buffer.push_and_pop(fake_image_A)\n",
    "        fake_output_A = netD_A(fake_image_A.detach())\n",
    "        errD_fake_A = adversarial_loss(fake_output_A, fake_label)\n",
    "\n",
    "        # Combined loss and calculate gradients\n",
    "        errD_A = (errD_real_A + errD_fake_A) / 2\n",
    "\n",
    "        # Calculate gradients for D_A\n",
    "        errD_A.backward()\n",
    "        # Update D_A weights\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (3) Update D network: Discriminator B\n",
    "        ##############################################\n",
    "\n",
    "        # Set D_B gradients to zero\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real B image loss\n",
    "        real_output_B = netD_B(real_image_B)\n",
    "        errD_real_B = adversarial_loss(real_output_B, real_label)\n",
    "\n",
    "        # Fake B image loss\n",
    "        fake_image_B = fake_B_buffer.push_and_pop(fake_image_B)\n",
    "        fake_output_B = netD_B(fake_image_B.detach())\n",
    "        errD_fake_B = adversarial_loss(fake_output_B, fake_label)\n",
    "\n",
    "        # Combined loss and calculate gradients\n",
    "        errD_B = (errD_real_B + errD_fake_B) / 2\n",
    "\n",
    "        # Calculate gradients for D_B\n",
    "        errD_B.backward()\n",
    "        # Update D_B weights\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        progress_bar.set_description(\n",
    "            f\"[{epoch}/{epochs_total - 1}][{i}/{len(dataloader) - 1}] \"\n",
    "            f\"Loss_D: {(errD_A + errD_B).item():.4f} \"\n",
    "            f\"Loss_G: {errG.item():.4f} \"\n",
    "            f\"Loss_G_identity: {(loss_identity_A + loss_identity_B).item():.4f} \"\n",
    "            f\"loss_G_GAN: {(loss_GAN_A2B + loss_GAN_B2A).item():.4f} \"\n",
    "            f\"loss_G_cycle: {(loss_cycle_ABA + loss_cycle_BAB).item():.4f}\")\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            vutils.save_image(real_image_A,\n",
    "                              f\"{output_dir}/{dataset_name}/A/real_samples.png\",\n",
    "                              normalize=True)\n",
    "            vutils.save_image(real_image_B,\n",
    "                              f\"{output_dir}/{dataset_name}/B/real_samples.png\",\n",
    "                              normalize=True)\n",
    "\n",
    "            fake_image_A = 0.5 * (netG_B2A(real_image_B).data + 1.0)\n",
    "            fake_image_B = 0.5 * (netG_A2B(real_image_A).data + 1.0)\n",
    "\n",
    "            vutils.save_image(fake_image_A.detach(),\n",
    "                              f\"{output_dir}/{dataset_name}/A/fake_samples_epoch_{epoch}.png\",\n",
    "                              normalize=True)\n",
    "            vutils.save_image(fake_image_B.detach(),\n",
    "                              f\"{output_dir}/{dataset_name}/B/fake_samples_epoch_{epoch}.png\",\n",
    "                              normalize=True)\n",
    "\n",
    "    # do check pointing\n",
    "    torch.save(netG_A2B.state_dict(), f\"weights/{dataset_name}/netG_A2B_epoch_{epoch}.pth\")\n",
    "    torch.save(netG_B2A.state_dict(), f\"weights/{dataset_name}/netG_B2A_epoch_{epoch}.pth\")\n",
    "    torch.save(netD_A.state_dict(), f\"weights/{dataset_name}/netD_A_epoch_{epoch}.pth\")\n",
    "    torch.save(netD_B.state_dict(), f\"weights/{dataset_name}/netD_B_epoch_{epoch}.pth\")\n",
    "\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "# save last check pointing\n",
    "torch.save(netG_A2B.state_dict(), f\"weights/{dataset_name}/netG_A2B.pth\")\n",
    "torch.save(netG_B2A.state_dict(), f\"weights/{dataset_name}/netG_B2A.pth\")\n",
    "torch.save(netD_A.state_dict(), f\"weights/{dataset_name}/netD_A.pth\")\n",
    "torch.save(netD_B.state_dict(), f\"weights/{dataset_name}/netD_B.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
